\documentclass[12pt]{article}
\usepackage[spanish]{babel}
\usepackage{makeidx}
\usepackage[margin=1in]{geometry}  % set the margins to 1in on all sides
\usepackage{graphicx}              % to include figures
\usepackage{amsmath}               % great math stuff
\usepackage{amsfonts}              % for blackboard bold, etc
\usepackage{amsthm}                % better theorem environments
\usepackage{makeidx}               % index
\usepackage[utf8]{inputenc}        % now we have tildes!
\usepackage{wrapfig}               % images
\usepackage{listings}              % Unordered lists
\usepackage{hyperref}              % hyperlinks
\usepackage{xcolor}                % to colorize font
\usepackage{blindtext}             % to colorize font

\makeindex

\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\textsc{\LARGE Universidad Carlos III de Madrid}\\[1.2cm] % Name of your university/college

%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\includegraphics[width=9cm]{Logo}\\[1.2cm] % Include a department/university logo - this will require the graphicx package

\textsc{\Large Aprendizaje Automático}\\[0.5cm] % Major heading such as course name
\textsc{\large Grado en Ingeniería Informática}\\[0.6cm] % Minor heading such as course title
\textsc{\large Grupo 83}\\[0.5cm]

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.7cm]
{ \huge \bfseries Práctica 2: Aprendizaje basado en instancias}\\[0.4cm] % Title of your document
\HRule \\[0.7cm]

%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\textit{Autores:}\\
Daniel \textsc{Medina García}\\ % Your name
Alejandro \textsc{Rodríguez Salamanca}\\[1.1cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\ % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\tableofcontents

\newpage
\thispagestyle{empty}
\clearpage
\vspace*{\fill}
\begin{center}
    \begin{minipage}{\textwidth}
        \begin{center}
            \section*{Introducción}
            El presente documento contiene la memoria del trabajo realizado para esta segunda práctica de Aprendizaje Automático. En ella, el equipo ha utilizado el aprendizaje basado en instancias, haciendo uso de la técnica de \textit{clustering} para poder implementar funciones de afinidad y agilizar así la clasificación. Continuamos así nuestra introducción al aprendizaje no supervisado, en oposición al aprendizaje supervisado visto en ejercicios anteriores.
        \end{center}
    \end{minipage}
\end{center}
\vfill

\newpage
\section{Recogida de información}

% Descripción de las variables que representan el estado, así como su rango de valores.

Tomamos como base la toma de datos de la anterior práctica, para construir sobre ella ligeras mejoras que en nuestra opinión optimizaban la información almacenada. Así, los siguientes datos fueron recopilados en tiempo de ejecución:

\begin{itemize}
    \item \texttt{score} : atributo numérico que contiene la puntuación instantánea. Su rango tiene cota una superior marcada por el número de fantasmas con el que se jueguen (cada fantasma aporta 250 puntos) y no tiene cota inferior, ya que cada turno que pase \textit{PacMan} sin comer perderá un punto.
    \item \texttt{ghosts-living} : atributo numérico que lleva la cuenta de los fantasmas que quedan vivos en el momento actual. Su valor oscila entre 1 (sólo queda un fantasma por cazar) y 4 (situación inicial).
    \item \texttt{distance-ghost}$_{i}$ : cuatro atributos numéricos que hacen de vector de distancias a los respectivos fantasmas en este turno.
    \item \texttt{prev-distance-ghost}$_{i}$ : cuatro atributos numéricos que expanden la información desde el turno anterior para evaluar el acercamiento o distanciamiento a los fantasmas. Todas las distancias tienen como mínimo 1 y la diagonal del tablero como máximo.
    \item \texttt{pos\textless axis\textgreater} : coordenadas de PacMan, en forma de número entero. Sus valores se encuentran dentro del rango de los ejes \textit{X} e \textit{Y} del mapa de juego.
    \item \texttt{direction} : atributo enumerado que indica el anterior movimiento de PacMan, comprendido entre los cinco posibles valores \textit{North, South, East, West} y \textit {Stop}.
    \item \texttt{wall-\textless direction\textgreater} : 4 atributos enumerados en forma booleano que indican si hay o no un muro en las posiciones contiguas a PacMan.
    \item \texttt{move} : Acción que toma el agente en el turno actual, con posibles valores \textit{North, South, East, West} y \textit {Stop}, si bien esperamos que esta última no sea tomada nunca.
    \item En continuación de la parte de predicción de la \textit{Práctica 1}, almacenamos seguidamente todos los atributos mencionados hasta ahora a tres turnos vista. Estos atributos pueden verse en el archivo como \textless atributo\textgreater N, indicando que es el atributo del turno futuro.
    \item \texttt{fx} : valor de la función de evaluación, que explicaremos más adelante.
\end{itemize}

\noindent Para optimizar la recogida de datos, además:
\begin{itemize}
    \item Si el movimiento que realiza PacMan es \textit{Stop}, no lo escribimos. Esto es debido a que no queremos que nuestro agente se quede parado en mitad de la partida.
    \item Si el valor de la función es menor que en el turno anterior, no guardamos la instancia, ya que consideramos que el movimiento que se ha realizado no ha sido bueno.
\end{itemize}

\newpage
\section{Clustering}

% Descripción y justificación de los algoritmos utilizados para el proceso de \textit{clustering}.

Tras probar todos los diferentes algoritmos de \textit{clustering} ofrecidos por \textit{Weka}, hicimos un primer filtro con aquellos que nos daban un número manejable de \textit{clusters} (o se podía configurar dicho número) para evitar aquellos que generaban demasiados (menos de un 5\% de pertenencia) o insuficientes (menos de 4). Esta primera selección nos dejó con \textit{Cobweb}, \textit{EM}, \textit{FarthestFirst} y \textit{SimpleKMeans}. Comparando los algoritmos, buscamos dos propiedades: equilibrio entre los \textit{clusters} y ``estabilidad'' entre ejecuciones al modificar los parámetros (i.e. semilla u otras constantes). Esta comparativa nos hizo decantarnos por \textit{SimpleKMeans} y \textit{EM}, pues los porcentajes de pertenencia a cada \textit{cluster} eran más parecidos entre sí y distintas semillas resultaban en \textit{clusters} de dimensiones similares.

Si bien los resultados eran parecidos entre estos dos algoritmos, el elevado coste en tiempo para elaborar el \textit{clustering} con \textit{EM} nos hizo decantarnos por \textit{SimpleKMeans}. Mostramos a continuación la justificación de nuestra decisión, donde observamos el equilibrio conseguido con este algorimo de \textit{clustering} y su estabilidad ante el cambio de la semilla. Cabe destacar que con los otros algoritmos encontramos variaciones muy superiores (e.g. entre 11 y 17\% con \textit{FarthestFirst}, alcanzando el 15\% con \textit{Cobweb}), alejadas de la media de 6\% obtenida con \textit{SimpleKMeans}.

\begin{center}
    \includegraphics[width=15cm]{stdff}
\end{center}

% Descripción de cualquier tratamiento sobre los datos que se lleve a cabo y de todos los pasos realizados.

Para potenciar la eficacia de la clusterización, probamos a normalizar los datos. Sin embargo, los resultados obtenidos fueron los mismos. Como la normalización de los datos dificultaba la clasificación de nuevas instancias desde el wrapper de \textit{Weka} para \texttt{Python}, decidimos excluir este y otros filtros de preproceso de los datos.

Para determinar si los movimientos tomados habían sido o no buenos, elaboramos una función cuyo incremento entre turnos supondría un rendimiento productivo. Esta función, que consta de tres sumandos con un coeficiente a modo de peso para evaluar distintos aspectos del agente, nos ayudará a descartar las instancias que no consideremos que ayuden para clusterizar correctamente:

\begin{center}
    $ f(x) =  0,5*(\frac{distancia_{cercano}}{diagonal})^{-1}\ +\ 0,2*(\frac{distancia_{media}}{diagonal})^{-1}\ +\ 0,3*\frac{fantasmas_{muertos}}{fantasmas_{Iniciales}} $
\end{center}

\begin{itemize}
    \item En primer lugar, hacemos visible el acercamiento al fantasma más cercano normalizando la distancia a la que se encuentra PacMan de éste. Tomar la inversa de este dato nos asegura que un incremento en la función supone un movimiento acertado.
    \item Para evaluar el rendimiento a largo plazo, introducimos también la media de distancias normalizadas a los fantasmas. De nuevo, la inversa nos proporciona el dato que queremos incrementar.
    \item Por último, no podemos olvidarnos del objetivo principal del PacMan. Así, incluimos la cuenta de los fantasmas comidos en el último turno.
\end{itemize}

Al considerar de distinta imporancia los diferentes aspectos evaluados, incluimos los pesos de \textbf{0'5, 0'2 y 0'3} respectivamente a los sumandos previamente mencionados.

% Descripción de las estructuras de datos utilizadas para el almacenamiento de la información generada en el proceso de clustering.

Las instancias pertenecientes a cada \textit{cluster} son almacenadas en un array bidimensional: la primera dimensión indica el \textit{cluster} y la segunda indica el índice de cada instancia dentro del cluster. A través del wrapper clusterizamos los datos de entrada al inicializar el agente automático, y según resulten en uno u otro \textit{cluster} son añadidos a un u otro array.

% Descripción de la función de pertenencia al \textit{cluster}implementada.

En cuanto a la selección del \textit{cluster} para cada instancia utilizamos, como anteriormente mencionamos, el algoritmo \textit{SimpleKMeans} proporcionado por \textit{Weka}, con 10 \textit{clusters} y semilla igual a 4. El número de \textit{clusters} se ha escogido teniendo en cuenta que tenemos cuatro movimientos posibles, y varias situaciones posibles por las cuales tomar dichos movimientos, por lo que consideramos que 10 podía ser un número suficientemente significativo como para separar los datos, dato que posteriormente hemos podido comprobar con \textit{Weka}, obteniendo los siguientes resultados:

\begin{center}
    \begin{tabular}{c | c}
        \hline
        Cluster & Porcentaje \\
        \hline
        0   &    8\% \\
        1   &   10\% \\
        2   &   15\% \\
        3   &    5\% \\
        4   &    7\% \\
        5   &    7\% \\
        6   &   16\% \\
        7   &   13\% \\
        8   &   11\% \\
        9   &   10\% \\
    \end{tabular}
\end{center}

\newpage
\section{Generación del agente automático}

Una vez generados los \textit{clusters} en los cuales separamos los datos entre los que clasificaremos las instancias nuevas, pasamos a lo que realmente integra la elección de la acción a tomar.

Para generar nuestro agente, hemos usado el \textit{wrapper} de \textit{Weka} para \texttt{Python}.

\begin{enumerate}
    \item Primero, cargamos el archivo \texttt{.arff} que contiene nuestras instancias, y haciendo uso de la clase \texttt{Clusterer} de \texttt{Weka}, generamos el \textit{cluster}.
    \item Después, sobre los datos previamente cargados en el programa, aplicamos el filtro \texttt{AddCluster}, que asignará a cada instancia su correspondiente \textit{clusters}, para que luego podamos comparar estas instancias con las nuevas.
    \item Tras este proceso, guardamos en una matriz las instancias separadas por \textit{cluster}, tal y como hemos explicado previamente.
    \item Finalmente, cada vez que recibimos una nueva instancia en una partida, llamamos al método \texttt{cluster\_instance} de la clase \texttt{Clusterer}, al cual le pasamos la instancia, y nos devolverá el index del cluster al que ésta pertenece.
\end{enumerate}

Una vez sabemos a qué \textit{cluster} pertenece nuestra nueva instancia, recorremos la fila correspondiente de la matriz previamente descrita, comparando todas las instancias contenidas en el \textit{cluster} con nuestra nueva instancia haciendo uso de la función de similitud que explicaremos a continuación, obteniendo un valor numérico que indica el parecido que existe entre las dos instancias.

% Descripción de la función de similitud entre instancias implementada.

La \textbf{función de similitud} implementada asigna pesos a los diferentes atributos guardados de cada instancia para determinar un punto para cada instancia cuya distancia euclídea ponderada con otra instancia determinará cómo de afín le es. Repartimos los pesos según lo que consideramos ``áreas de conocimiento", o grupos de atributos que contienen una misma información. De esta forma, agrupamos la puntuación, las distancias a los fantasmas, la posición de \textit{PacMan}, la dirección y la existencia de muros alrededor, quedando de la siguiente forma:
\begin{center}
    $ fSimilitud(instancia) = 0.2 * fantasmas_{vivos}\ +\ 0.2 * \sum\limits_{i = 0}^{fantasmas_{vivos}} distancia_i\ +\ 0.2 *  (pos_X + pos_Y)\ +\ 0.2 * direccion\ +\ 0.2 * \sum\limits_{i = 0}^{dimension_{tablero}} hayMuro_i $
\end{center}

\begin{itemize}
    \item Sumando 1: número de fantasmas que están vivos.
    \item Sumando 2: suma de las distancias a los fantasmas vivos
    \item Sumando 3: suma de las coordenadas \textit{X} e \textit{Y} de \textit{PacMan}.
    \item Sumando 4: valor numérico que asignamos a cada una de las diferentes direcciones, \textit{Stop} (4), \textit{East} (3), \textit{West} (2), \textit{South} (1), y \textit{North} (0).
    \item Sumando 5: sumatorio sobre la lista de muros alrededor de \textit{PacMan}. Si existe un muro (\textit{True}), sumamos 1, si no existe (\textit{False}), el valor se mantiene.
\end{itemize}

\newpage
\subsection{Preguntas propuestas:}

\vspace{0.5cm}
\begin{center}
    \textbf{¿Por qué ha sido útil realizar \textit{clustering} previa de las instancias?}
\end{center}
\vspace{0.5cm}

El uso de \textit{clusters} permite ahorrar bastante tiempo en comparaciones para la clasificación. Al tener \textit{clusters} ya hechos, sólo se compara la instancia nueva con aquellas que pertenezcan al mismo \textit{cluster} en lugar de con todo el set de entrenamiento, sabiendo que la instancia más cercana se hallará en dicho cluster.

\vspace{0.5cm}
\begin{center}
    \textbf{¿Por qué es importante usar pocos atributos en técnicas de aprendizaje no supervisado?}
\end{center}
\vspace{0.5cm}

El aprendizaje no supervisado busca redundancias entre las instancias que indiquen algún criterio con el que diferenciar grupos que permitan agrupar estos ejemplos en grupos. Encontrar redundancias es un proceso cuya dificultad crece de forma exponencial con respecto al número de atributos que se tienen en cuenta, por lo que minimizar el número de atributos con los que se hacen los \textit{clusters} optimizará notablemente el proceso.

\vspace{0.5cm}
\begin{center}
    \textbf{¿Qué ventaja tiene el uso del aprendizaje basado en instancias con respecto al visto en la práctica 1?}
\end{center}
\vspace{0.5cm}

El aprendizaje no supervisado tiene como ventaja que no requiere datos previamente etiquetados sino que es el propio algoritmo el que busca el \textit{grupo de datos} al que pertenece sin necesidad de saber los grupos que existen.

\vspace{0.5cm}
\begin{center}
    \textbf{¿Consideras que el agente funcionaría mejor si se introdujesen más ejemplos? ¿Por qué?}
\end{center}
\vspace{0.5cm}

El proceso de creación de \textit{clusters} se basa en la búsqueda de redundancia entre instancias, por lo que un conjunto de entrenamiento más grande podría ayudar a formar \textit{clusters} más informados. Cuantas más instancias tenga el proceso de clusterización más definidos estarán los grupos si los hay; si, por el contrario, los grupos no están definidos con un numero cuantioso de instacias, puede significar que los atributos recopilados no aporten la suficiente información como para separar las instancias como queremos y debamos buscar otro enfoque distinto para poder diferenciar instancias.

\newpage
\section{Evaluación de los agentes}

% TODO Será necesario evaluar el aprendizaje del agente automático de esta práctica. Para ello hay que realizar las siguientes tareas:

% Descripción y análisis de los resultados obtenidos en la fase de evaluación.
Una vez generado el nuevo agente, llegó la parte más esperada. Realmente nos intrigaba ver cómo respondería el nuevo agente en acción en comparación al desarrollado en la práctica anterior al haber utilizado técnicas tan distintas para decidir qué acción tomar.

% 3. Evaluar para cada uno de los agentes, cómo evoluciona la distancia recorrida y enemigos muertos en cada instante de cada partida. Para ello realizar una gráfica o una tabla donde se muestre por un lado el tiempo vs distancia y otra con los fantasmas vs tiempo. Se recomienda hacer una media de todas las partidas jugadas, con lo que se realizarán dos gráficas por agente.

Para evaluar el agente generado, se puso a jugar partidas a los tres agentes en distintos escenarios para poder comparar distintas situaciones y comprender globalmente los resultados.

Para ejecutar el agente, es necesario seguir lo siguientes pasos:
\begin{enumerate}
    \item Instalar las dependencias y el wrapper de \textit{Weka} para \texttt{Python}.\footnote{https://pythonhosted.org/python-weka-wrapper/install.html}
    \item Ejecutar el comando \texttt{python busters.py -p ClusteredAgent}
\end{enumerate}

Así, nuestro agente buscará en la carpeta \texttt{data/} el fichero \texttt{game\_toCluster.arff} para crear el \textit{cluster} y poder clasificar las nuevas instancias. A continuación se muestra una gráfica que ilustra cuántos turnos tardó cada agente en llegar a todos los fantasmas:

\begin{center}
    \includegraphics[width=16.7cm]{performance}
\end{center}

El agente de teclado (humano), al contar con la información extra de dónde está cada uno de los fantasmas en cada momento, es capaz de obtener un rendimiento bastante mejor (rozando el óptimo). Sin embargo, comparando los dos agentes automáticos observamos una \textbf{mejora muy clara} del nuevo agente respecto al anterior, de en torno al 60\%. En la siguiente gráfica mostramos la desviación estándar de los resultados de la gráfica anterior para poder ver con perspectiva los datos obtenidos. En ella, podemos ver que el agente de la \textit{Práctica 1} se aleja considerablemente de un comportamiento determinista, con grandes diferencias entre los resultados de cada partida. Esto confirma también que nuestro nuevo agente toma decisiones mucho más informadas, consiguiendo una desviación mucho menor en sus resultados.

\begin{center}
    \includegraphics[width=16.7cm]{stdDev}
\end{center}

Sorprendidos con esta mejora tan llamativa, pasamos a comparar el tiempo empleado en cada turno para tomar la decisión que indicará a PacMan qué acción tomar. La siguiente gráfica compara el tiempo medio de respuesta de cada agente:

% TODO: la gráfica que está ahora compara sólo los <agente>classic.csv. Hacer una gráfica que contenga la media de cada uno de los agentes jugando varias partidas en 2 o 3 mapas de dimensiones parecidas (trickyClassic, openHunt y default)

\begin{center}
    \includegraphics[width=16.7cm]{tiempoRespuesta}
\end{center}

Curiosamente, si bien el rendimiento comprobábamos que se había incrementado considerablemente con el agente que utiliza aprendizaje no supervisado, ahora observamos una \textbf{eficiencia mucho menor} en esta implementación. La causa de esta contrapartida es la cantidad de cómputo realizada por este agente en comparación con los otros dos:
\begin{itemize}
    \item El agente \textbf{humano} toma como tiempo de computación tan sólo lo que tarda el proceso de \texttt{Python} en recibir e interpretar la tecla del teclado que ha pulsado el humano, siendo este un intervalo ínfimo, despreciable.
    \item El agente de la \textbf{Práctica 1} genera un árbol de clasificación al iniciar el juego con los datos que tenía antes de empezar una partida y, una vez generado, lo utiliza para clasificar cada nueva instancia. De esta forma, el tiempo real de cómputo se encuentra en la inicialización del agente, dejando para cada turno tan sólo el ``descenso'' del árbol de la nueva instancia que ``caerá'' en una clase o en otra.
    \item Sin embargo, el agente de esta \textbf{Práctica 2} compara, en cada turno, la nueva instancia con todas aquellas contenidas en el \textit{cluster} al que se le ha asignado para ver cuál de ellas se le parece más. Esto requiere calcular la función de similitud por cada una de las instancias del clúster, lo que supone un tiempo muy elevado en cuanto a cómputo.
\end{itemize}

Más allá de los análisis previamente mostrados, la siguiente gráfica ilustra el tiempo de ejecución versus la distancia recorrida por el agente:

\begin{center}
    \includegraphics[width=16.7cm]{tiempoVsDistancia}
\end{center}

En esta última comparación observamos cómo los tiempos de ejecución se mantienen bastante constantes a lo largo de toda la ejecución del programa. Mostramos sólo hasta el turno 2500 ya que sólo el agente de la \textit{Práctica 1} continúa más allá y no es éste el que nos interesa evaluar.


\newpage
\section{Conclusiones}

El modelo obtenido en esta práctica puede ser útil como parte del agente automático para el juego de PacMan original, así como para otros juegos donde el agente tenga que moverse y perseguir objetivos. Comparando la eficiencia del agente previo al desarollado en esta práctica pensamos que una implementación de un agente automático basado en aprendizaje supervisado puede ser mucho más rápido que otro basado en aprendizaje no supervisado, pero a cambio requiere un modelo mucho mejor formado. Confiamos que con un estudio más experto de los datos a tener en cuenta para la elaboración del modelo de clasificación, así como un mayor conjunto de datos de entrenamiento, podría dar como resultado un agente tan eficiente como otro que basa su conocimiento en aprendizaje no supervisado, siendo mucho más rápido en la toma de decisiones.

Al realizar la práctica hemos entendido campos donde podrían usarse técnicas de aprendizaje automático como el cálculo de rutas en tiempo real para un vehículo que se mueve por un entorno.

\vspace{0.5cm}
\centerline{\textbf{Uso de \textit{Weka} en \texttt{Python}}}
\vspace{0.5cm}

El mayor beneficio que nos ha aportado usar el wrapper de \textit{Weka} a la hora de generar nuestro agente, es que si en algún momento queremos cambiar el algoritmo de \textit{clustering}, sólo tenemos que editar una línea de código. Por otra parte, si lo que queremos es obtener más datos para realizar el \textit{cluster}, es tan sencillo como añadirlos a nuestro archivo \texttt{.arff}. Gracias a esto, hemos podido cambiar y probar diversas opciones y algoritmos sin necesidad de que la implementación de nuestro agente haya variado, lo que nos ha ahorrado mucho tiempo.

\vspace{0.5cm}
\centerline{\textbf{Problemas encontrados}}
\vspace{0.5cm}

Como de costumbre en tareas de aprendizaje automático, los problemas surgidos durante el desarrollo de la \textit{Práctica 2} han solido estar relacionados con los ``palos de ciego" necesarios para llegar a resultados concluyentes. Bajo el lema de ``prueba, error y aprendizaje", el equipo trabajó para afinar los resultados tanto como fuese razonable.

Además, el wrapper de \textit{Weka} nos ha vuelto a ocasionar algún contratiempo, tal y como en la práctica anterior, por la falta de ejemplos disponibles y su escasa documentación.

\vspace{0.5cm}
\centerline{\textbf{Comentarios personales}}
\vspace{0.5cm}

Nos ha parecido muy interesante cómo la combinación de diferentes técnicas da como resultado una búsqueda más eficiente de soluciones, como en esta práctica el procesamiento de asociación en \textit{clusters} de los datos para reducir el dominio de búsqueda para la clasificación de una instancia. Este encuentro con el aprendizaje no supervisado nos ayudará a tener más herramientas a la hora de solucionar futuros problemas.

\end{document}
